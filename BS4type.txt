for page_num in range(1, 100):
    http = requests.get(
        "https://github.com" + page,
        # 'https://github.com/apache/iotdb/issues',
        headers=headers,
        # timeout=5
    )
    soup = BeautifulSoup(http.content, 'lxml')
    try:
        page = soup.find('a', attrs={
            'class': 'next_page'}).get('href')
    except:
        break
    finally:
        repo_name = soup.find_all(
            'a',
            attrs={'class': 'd-inline-block',
                   'data-hovercard-type': 'repository'}
        )
        print(len(repo_name))
